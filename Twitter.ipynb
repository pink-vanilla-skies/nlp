{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Twitter.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pink-vanilla-skies/nlp/blob/master/Twitter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcb-h-1Gwu7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install gensim --upgrade\n",
        "!pip install keras --upgrade\n",
        "!pip install pandas --upgrade"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1R-xMRYovRwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-chZKAvVvSMm",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzlxNBM5vSmV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mck0BLLqwz7m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DataFrame\n",
        "import pandas as pd\n",
        "\n",
        "# Matplot\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Scikit-learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense, Dropout, Embedding, Flatten, Conv1D, MaxPooling1D, LSTM\n",
        "from keras import utils\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "# nltk\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from  nltk.stem import SnowballStemmer\n",
        "\n",
        "# Word2vec\n",
        "import gensim\n",
        "\n",
        "# Utility\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "from collections import Counter\n",
        "import logging\n",
        "import time\n",
        "import pickle\n",
        "import itertools\n",
        "\n",
        "# Set log\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUAwLB7gxLdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXPMh5g3xQD-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DATASET\n",
        "DATASET_COLUMNS = [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n",
        "DATASET_ENCODING = \"ISO-8859-1\"\n",
        "TRAIN_SIZE = 0.8\n",
        "\n",
        "# TEXT CLENAING\n",
        "TEXT_CLEANING_RE = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\n",
        "\n",
        "# WORD2VEC \n",
        "W2V_SIZE = 300\n",
        "W2V_WINDOW = 7\n",
        "W2V_EPOCH = 32\n",
        "W2V_MIN_COUNT = 10\n",
        "\n",
        "# KERAS\n",
        "SEQUENCE_LENGTH = 300\n",
        "EPOCHS = 8\n",
        "BATCH_SIZE = 1024\n",
        "\n",
        "# SENTIMENT\n",
        "POSITIVE = \"POSITIVE\"\n",
        "NEGATIVE = \"NEGATIVE\"\n",
        "NEUTRAL = \"NEUTRAL\"\n",
        "SENTIMENT_THRESHOLDS = (0.4, 0.7)\n",
        "\n",
        "# EXPORT\n",
        "KERAS_MODEL = \"model.h5\"\n",
        "WORD2VEC_MODEL = \"model.w2v\"\n",
        "TOKENIZER_MODEL = \"tokenizer.pkl\"\n",
        "ENCODER_MODEL = \"encoder.pkl\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsLaPpFCxYVj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1Xm0cyRxeAd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "uploaded = files.upload()\n",
        "import io"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWMhf7OKyEpS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(io.BytesIO(uploaded['train.csv']), encoding =DATASET_ENCODING , names=DATASET_COLUMNS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ue9raNkAGoU9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l51LIb7wGvN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Dataset size:\", len(df))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-wIsedpG2jC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decode_map = {0: \"NEGATIVE\", 2: \"NEUTRAL\", 4: \"POSITIVE\"}\n",
        "def decode_sentiment(label):\n",
        "    return decode_map[int(label)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5iqJr4HG7ap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "df.target = df.target.apply(lambda x: decode_sentiment(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17Q8w40jG-vA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_cnt = Counter(df.target)\n",
        "\n",
        "plt.figure(figsize=(16,8))\n",
        "plt.bar(target_cnt.keys(), target_cnt.values())\n",
        "plt.title(\"Dataset labels distribuition\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zWbxVNTHD_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words = stopwords.words(\"english\")\n",
        "stemmer = SnowballStemmer(\"english\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DYf79wkHNMG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(text, stem=False):\n",
        "    # Remove link,user and special characters\n",
        "    text = re.sub(TEXT_CLEANING_RE, ' ', str(text).lower()).strip()\n",
        "    tokens = []\n",
        "    for token in text.split():\n",
        "        if token not in stop_words:\n",
        "            if stem:\n",
        "                tokens.append(stemmer.stem(token))\n",
        "            else:\n",
        "                tokens.append(token)\n",
        "    return \" \".join(tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbOiByJAHQOo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "df.text = df.text.apply(lambda x: preprocess(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34mQqY93HTH_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train, df_test = train_test_split(df, test_size=1-TRAIN_SIZE)\n",
        "print(\"TRAIN size:\", len(df_train))\n",
        "print(\"TEST size:\", len(df_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y89U6VsCHhJ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "documents = [_text.split() for _text in df_train.text] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uABFYNsvHlZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w2v_model = gensim.models.word2vec.Word2Vec(size=W2V_SIZE, \n",
        "                                            window=W2V_WINDOW, \n",
        "                                            min_count=W2V_MIN_COUNT, \n",
        "                                            workers=8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wdp4cEEHHp9p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w2v_model.build_vocab(documents)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38VoBWm2HsOc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = w2v_model.wv.vocab.keys()\n",
        "vocab_size = len(words)\n",
        "print(\"Vocab size\", vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFaui0LDH4M8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "w2v_model.train(documents, total_examples=len(documents), epochs=W2V_EPOCH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJPNCinSH8yY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w2v_model.most_similar(\"love\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUbISYEPNiib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(df_train.text)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(\"Total words\", vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qA-2QGuNn4W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "x_train = pad_sequences(tokenizer.texts_to_sequences(df_train.text), maxlen=SEQUENCE_LENGTH)\n",
        "x_test = pad_sequences(tokenizer.texts_to_sequences(df_test.text), maxlen=SEQUENCE_LENGTH)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohSs_wAdNvGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = df_train.target.unique().tolist()\n",
        "labels.append(NEUTRAL)\n",
        "labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txu0xNaDOEzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = LabelEncoder()\n",
        "encoder.fit(df_train.target.tolist())\n",
        "\n",
        "y_train = encoder.transform(df_train.target.tolist())\n",
        "y_test = encoder.transform(df_test.target.tolist())\n",
        "\n",
        "y_train = y_train.reshape(-1,1)\n",
        "y_test = y_test.reshape(-1,1)\n",
        "\n",
        "print(\"y_train\",y_train.shape)\n",
        "print(\"y_test\",y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aw8TZwraOTm_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"x_train\", x_train.shape)\n",
        "print(\"y_train\", y_train.shape)\n",
        "print()\n",
        "print(\"x_test\", x_test.shape)\n",
        "print(\"y_test\", y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoOrKfGFOV0w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQy9woYjOYSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_matrix = np.zeros((vocab_size, W2V_SIZE))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "  if word in w2v_model.wv:\n",
        "    embedding_matrix[i] = w2v_model.wv[word]\n",
        "print(embedding_matrix.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kev_UbqaObL8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_layer = Embedding(vocab_size, W2V_SIZE, weights=[embedding_matrix], input_length=SEQUENCE_LENGTH, trainable=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vBvyoa0OesT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(embedding_layer)\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0sin3z6OiOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=\"adam\",\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrAxpZmWOntB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks = [ ReduceLROnPlateau(monitor='val_loss', patience=5, cooldown=0),\n",
        "              EarlyStopping(monitor='val_acc', min_delta=1e-4, patience=5)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_f9--J4yOxEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_split=0.1,\n",
        "                    verbose=1,\n",
        "                    callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69u_YS28O19E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%timeBM.\n",
        "score = model.evaluate(x_test, y_test, batch_size=BATCH_SIZE)\n",
        "print()\n",
        "print(\"ACCURACY:\",score[1])\n",
        "print(\"LOSS:\",score[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWcj40TGjl1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive \n",
        "from google.colab import auth \n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uks9cxhj8LR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jiko84i2kMur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('model.h5')\n",
        "model_file = drive.CreateFile({'title' : 'model.h5'})\n",
        "model_file.SetContentFile('model.h5')\n",
        "model_file.Upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvilZiiJla2S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# download to google drive\n",
        "drive.CreateFile({'id': model_file.get('id')})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooqxdIuylwtX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_obj = drive.CreateFile({'id': '1TAdHwmvn97QSKBTlaBH3dt_vXwhPN7FQ'})\n",
        "file_obj.GetContentFile('model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejkdGMAJl-BD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sentiment(score, include_neutral=True):\n",
        "    if include_neutral:        \n",
        "        label = NEUTRAL\n",
        "        if score <= SENTIMENT_THRESHOLDS[0]:\n",
        "            label = NEGATIVE\n",
        "        elif score >= SENTIMENT_THRESHOLDS[1]:\n",
        "            label = POSITIVE\n",
        "\n",
        "        return label\n",
        "    else:\n",
        "        return NEGATIVE if score < 0.5 else POSITIVE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VETukXp-mEEi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(text, include_neutral=True):\n",
        "    start_at = time.time()\n",
        "    # Tokenize text\n",
        "    x_test = pad_sequences(tokenizer.texts_to_sequences([text]), maxlen=SEQUENCE_LENGTH)\n",
        "    # Predict\n",
        "    score = model.predict([x_test])[0]\n",
        "    # Decode sentiment\n",
        "    label = decode_sentiment(score, include_neutral=include_neutral)\n",
        "\n",
        "    return {\"label\": label, \"score\": float(score),\n",
        "       \"elapsed_time\": time.time()-start_at}  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbyTh7i0mg7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict(\"i dont love the new iphone 11 max pro\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rS03Vzqmjwk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(KERAS_MODEL)\n",
        "w2v_model.save(WORD2VEC_MODEL)\n",
        "pickle.dump(tokenizer, open(TOKENIZER_MODEL, \"wb\"), protocol=0)\n",
        "pickle.dump(encoder, open(ENCODER_MODEL, \"wb\"), protocol=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk07lAdjm8yO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "model2 = Sequential()\n",
        "model2 = load_model('/content/model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5AUREZCn5Ui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = 'i do not love the new iphone 11 that much'\n",
        "x_test = pad_sequences(tokenizer.texts_to_sequences([text]), maxlen=SEQUENCE_LENGTH)\n",
        "# Predict\n",
        "score = model2.predict([x_test])[0]\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHKpcalsozf9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"dgfd\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0mYJhl9Cr6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}